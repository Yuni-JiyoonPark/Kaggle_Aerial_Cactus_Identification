{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13435,"databundleVersionId":331452,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:13:00.093856Z","iopub.execute_input":"2025-02-04T01:13:00.094104Z","iopub.status.idle":"2025-02-04T01:13:01.388450Z","shell.execute_reply.started":"2025-02-04T01:13:00.094079Z","shell.execute_reply":"2025-02-04T01:13:01.387691Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/aerial-cactus-identification/sample_submission.csv\n/kaggle/input/aerial-cactus-identification/train.zip\n/kaggle/input/aerial-cactus-identification/test.zip\n/kaggle/input/aerial-cactus-identification/train.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:13:01.389228Z","iopub.execute_input":"2025-02-04T01:13:01.389584Z","iopub.status.idle":"2025-02-04T01:13:05.300895Z","shell.execute_reply.started":"2025-02-04T01:13:01.389560Z","shell.execute_reply":"2025-02-04T01:13:05.300026Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:16.555495Z","iopub.execute_input":"2025-02-04T01:14:16.555827Z","iopub.status.idle":"2025-02-04T01:14:16.564574Z","shell.execute_reply.started":"2025-02-04T01:14:16.555800Z","shell.execute_reply":"2025-02-04T01:14:16.563492Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:18.245480Z","iopub.execute_input":"2025-02-04T01:14:18.245770Z","iopub.status.idle":"2025-02-04T01:14:18.287383Z","shell.execute_reply.started":"2025-02-04T01:14:18.245748Z","shell.execute_reply":"2025-02-04T01:14:18.286464Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from zipfile import ZipFile\n\n# 훈련 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \n# 테스트 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:20.421397Z","iopub.execute_input":"2025-02-04T01:14:20.421711Z","iopub.status.idle":"2025-02-04T01:14:23.089728Z","shell.execute_reply.started":"2025-02-04T01:14:20.421692Z","shell.execute_reply":"2025-02-04T01:14:23.088821Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(labels, \n                                test_size=0.1,\n                                stratify=labels['has_cactus'],\n                                random_state=50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:29.749609Z","iopub.execute_input":"2025-02-04T01:14:29.750019Z","iopub.status.idle":"2025-02-04T01:14:29.760785Z","shell.execute_reply.started":"2025-02-04T01:14:29.749999Z","shell.execute_reply":"2025-02-04T01:14:29.759802Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"import cv2 # OpenCV 라이브러리\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__() # 상속받은 Dataset의 생성자 호출\n        # 전달받은 인수들 저장\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드 \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]    # 이미지 ID\n        img_path = self.img_dir + img_id # 이미지 파일 경로 \n        image = cv2.imread(img_path)     # 이미지 파일 읽기 \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        label = self.df.iloc[idx, 1]     # 이미지 레이블(타깃값)\n\n        if self.transform is not None:\n            image = self.transform(image) # 변환기가 있다면 이미지 변환\n        return image, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:41.007248Z","iopub.execute_input":"2025-02-04T01:14:41.007543Z","iopub.status.idle":"2025-02-04T01:14:41.438101Z","shell.execute_reply.started":"2025-02-04T01:14:41.007526Z","shell.execute_reply":"2025-02-04T01:14:41.437303Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Pad(32, padding_mode='symmetric'),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.Normalize((0.485, 0.456, 0.406),\n                                                           (0.229, 0.224, 0.225))])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test= transforms.Compose([transforms.ToTensor(),\n                                    transforms.Pad(32, padding_mode='symmetric'),\n                                    transforms.Normalize((0.485, 0.456, 0.406),\n                                                         (0.229, 0.224, 0.225))])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:14:55.662107Z","iopub.execute_input":"2025-02-04T01:14:55.662376Z","iopub.status.idle":"2025-02-04T01:14:58.202120Z","shell.execute_reply.started":"2025-02-04T01:14:55.662359Z","shell.execute_reply":"2025-02-04T01:14:58.201167Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"## 데이터셋 생성\n\ndataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:15:05.172699Z","iopub.execute_input":"2025-02-04T01:15:05.173074Z","iopub.status.idle":"2025-02-04T01:15:05.177068Z","shell.execute_reply.started":"2025-02-04T01:15:05.173057Z","shell.execute_reply":"2025-02-04T01:15:05.176164Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"## 로더 생성\n\nfrom torch.utils.data import DataLoader # 데이터 로더 클래스\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:15:12.020894Z","iopub.execute_input":"2025-02-04T01:15:12.021163Z","iopub.status.idle":"2025-02-04T01:15:12.026023Z","shell.execute_reply.started":"2025-02-04T01:15:12.021146Z","shell.execute_reply":"2025-02-04T01:15:12.024814Z"}},"outputs":[],"execution_count":11},{"cell_type":"markdown","source":"## 모델 생성","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nimport torch.nn.functional as F # 신경망 모듈에서 자주 사용되는 함수\n\nclass Model(nn.Module):\n    # 신경망 계층 정의\n    def __init__(self):\n        super().__init__() # 상속받은 nn.Module의 __init__() 메서드 호출\n        # 1 ~ 5번째 {합성곱, 배치 정규화, 최대 풀링} 계층 \n        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(32), # 배치 정규화\n                                    nn.LeakyReLU(), # LeakyReLU 활성화 함수\n                                    nn.MaxPool2d(kernel_size=2))\n\n        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(64),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(128),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(256),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(512),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        # 평균 풀링 계층 \n        self.avg_pool = nn.AvgPool2d(kernel_size=4) \n        # 전결합 계층\n        self.fc1 = nn.Linear(in_features=512 * 1 * 1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n\n    # 순전파 출력 정의 \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512 * 1 * 1) # 평탄화\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:15:34.377860Z","iopub.execute_input":"2025-02-04T01:15:34.378107Z","iopub.status.idle":"2025-02-04T01:15:34.385418Z","shell.execute_reply.started":"2025-02-04T01:15:34.378091Z","shell.execute_reply":"2025-02-04T01:15:34.384486Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:15:42.918135Z","iopub.execute_input":"2025-02-04T01:15:42.918476Z","iopub.status.idle":"2025-02-04T01:15:43.007069Z","shell.execute_reply.started":"2025-02-04T01:15:42.918444Z","shell.execute_reply":"2025-02-04T01:15:43.006005Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"## 모델 훈련","metadata":{}},{"cell_type":"code","source":"# 손실 함수\ncriterion = nn.CrossEntropyLoss()\n\n# 옵티마이저\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:16:09.500530Z","iopub.execute_input":"2025-02-04T01:16:09.500804Z","iopub.status.idle":"2025-02-04T01:16:09.505292Z","shell.execute_reply.started":"2025-02-04T01:16:09.500784Z","shell.execute_reply":"2025-02-04T01:16:09.504333Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"epochs = 70 # 총 에폭\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    epoch_loss = 0 # 에폭별 손실값 초기화\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in loader_train:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가\n        epoch_loss += loss.item() \n        # 역전파 수행\n        loss.backward()\n        # 가중치 갱신\n        optimizer.step()\n        \n    print(f'에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_loss/len(loader_train):.4f}')    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T01:16:18.190740Z","iopub.execute_input":"2025-02-04T01:16:18.191013Z","iopub.status.idle":"2025-02-04T06:47:08.018210Z","shell.execute_reply.started":"2025-02-04T01:16:18.190994Z","shell.execute_reply":"2025-02-04T06:47:08.016734Z"}},"outputs":[{"name":"stdout","text":"에폭 [1/70] - 손실값: 0.1287\n에폭 [2/70] - 손실값: 0.0657\n에폭 [3/70] - 손실값: 0.0480\n에폭 [4/70] - 손실값: 0.0416\n에폭 [5/70] - 손실값: 0.0337\n에폭 [6/70] - 손실값: 0.0346\n에폭 [7/70] - 손실값: 0.0314\n에폭 [8/70] - 손실값: 0.0270\n에폭 [9/70] - 손실값: 0.0251\n에폭 [10/70] - 손실값: 0.0260\n에폭 [11/70] - 손실값: 0.0228\n에폭 [12/70] - 손실값: 0.0228\n에폭 [13/70] - 손실값: 0.0195\n에폭 [14/70] - 손실값: 0.0206\n에폭 [15/70] - 손실값: 0.0200\n에폭 [16/70] - 손실값: 0.0172\n에폭 [17/70] - 손실값: 0.0158\n에폭 [18/70] - 손실값: 0.0171\n에폭 [19/70] - 손실값: 0.0164\n에폭 [20/70] - 손실값: 0.0162\n에폭 [21/70] - 손실값: 0.0137\n에폭 [22/70] - 손실값: 0.0147\n에폭 [23/70] - 손실값: 0.0124\n에폭 [24/70] - 손실값: 0.0116\n에폭 [25/70] - 손실값: 0.0136\n에폭 [26/70] - 손실값: 0.0113\n에폭 [27/70] - 손실값: 0.0123\n에폭 [28/70] - 손실값: 0.0127\n에폭 [29/70] - 손실값: 0.0114\n에폭 [30/70] - 손실값: 0.0111\n에폭 [31/70] - 손실값: 0.0096\n에폭 [32/70] - 손실값: 0.0097\n에폭 [33/70] - 손실값: 0.0100\n에폭 [34/70] - 손실값: 0.0100\n에폭 [35/70] - 손실값: 0.0090\n에폭 [36/70] - 손실값: 0.0097\n에폭 [37/70] - 손실값: 0.0074\n에폭 [38/70] - 손실값: 0.0073\n에폭 [39/70] - 손실값: 0.0069\n에폭 [40/70] - 손실값: 0.0101\n에폭 [41/70] - 손실값: 0.0071\n에폭 [42/70] - 손실값: 0.0096\n에폭 [43/70] - 손실값: 0.0077\n에폭 [44/70] - 손실값: 0.0076\n에폭 [45/70] - 손실값: 0.0071\n에폭 [46/70] - 손실값: 0.0061\n에폭 [47/70] - 손실값: 0.0055\n에폭 [48/70] - 손실값: 0.0066\n에폭 [49/70] - 손실값: 0.0053\n에폭 [50/70] - 손실값: 0.0057\n에폭 [51/70] - 손실값: 0.0037\n에폭 [52/70] - 손실값: 0.0077\n에폭 [53/70] - 손실값: 0.0065\n에폭 [54/70] - 손실값: 0.0058\n에폭 [55/70] - 손실값: 0.0055\n에폭 [56/70] - 손실값: 0.0058\n에폭 [57/70] - 손실값: 0.0051\n에폭 [58/70] - 손실값: 0.0058\n에폭 [59/70] - 손실값: 0.0069\n에폭 [60/70] - 손실값: 0.0048\n에폭 [61/70] - 손실값: 0.0039\n에폭 [62/70] - 손실값: 0.0040\n에폭 [63/70] - 손실값: 0.0045\n에폭 [64/70] - 손실값: 0.0041\n에폭 [65/70] - 손실값: 0.0048\n에폭 [66/70] - 손실값: 0.0063\n에폭 [67/70] - 손실값: 0.0036\n에폭 [68/70] - 손실값: 0.0050\n에폭 [69/70] - 손실값: 0.0038\n에폭 [70/70] - 손실값: 0.0034\n","output_type":"stream"}],"execution_count":17},{"cell_type":"markdown","source":"## 성능 검증","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수 임포트\n\n# 실제값과 예측 확률값을 담을 리스트 초기화\ntrue_list = []\npreds_list = []\n\nmodel.eval() # 모델을 평가 상태로 설정 \n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, labels in loader_valid:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1] # 예측 확률값\n        true = labels.cpu() # 실제값 \n        # 예측 확률값과 실제값을 리스트에 추가\n        preds_list.extend(preds)\n        true_list.extend(true)\n        \n# 검증 데이터 ROC AUC 점수 계산 \nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}')    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:47:16.361307Z","iopub.execute_input":"2025-02-04T06:47:16.361650Z","iopub.status.idle":"2025-02-04T06:47:27.070383Z","shell.execute_reply.started":"2025-02-04T06:47:16.361629Z","shell.execute_reply":"2025-02-04T06:47:27.068531Z"}},"outputs":[{"name":"stdout","text":"검증 데이터 ROC AUC : 0.9998\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', \n                            transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\n# 예측 수행\nmodel.eval() # 모델을 평가 상태로 설정\n\npreds = [] # 타깃 예측값 저장용 리스트 초기화\n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, _ in loader_test:\n        # 이미지 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 타깃값이 1일 확률(예측값)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        # preds에 preds_part 이어붙이기\n        preds.extend(preds_part)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:47:45.314151Z","iopub.execute_input":"2025-02-04T06:47:45.314606Z","iopub.status.idle":"2025-02-04T06:48:10.647328Z","shell.execute_reply.started":"2025-02-04T06:47:45.314576Z","shell.execute_reply":"2025-02-04T06:48:10.646119Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:49:27.210201Z","iopub.execute_input":"2025-02-04T06:49:27.210616Z","iopub.status.idle":"2025-02-04T06:49:27.249308Z","shell.execute_reply.started":"2025-02-04T06:49:27.210586Z","shell.execute_reply":"2025-02-04T06:49:27.248183Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-04T06:49:39.432074Z","iopub.execute_input":"2025-02-04T06:49:39.432526Z","iopub.status.idle":"2025-02-04T06:49:40.359785Z","shell.execute_reply.started":"2025-02-04T06:49:39.432486Z","shell.execute_reply":"2025-02-04T06:49:40.358551Z"}},"outputs":[],"execution_count":21}]}